{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the environment\n",
    "%load_ext rpy2.ipython\n",
    "import rpy2.robjects as robjects\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "from scipy import optimize\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "from rpy2.robjects import pandas2ri\n",
    "import rpy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Imports for STM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in os.listdir(\"R\"):\n",
    "    if f not in ['.DS_Store', '.Rapp.history', 'box', 'e_step_spark.R']:\n",
    "        robjects.r.source(\"R/\" + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['splines', 'stringr', 'Matrix', 'tools', 'stats', 'graphics',\n",
       "       'grDevices', 'utils', 'datasets', 'methods', 'base'], \n",
       "      dtype='|S9')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robjects.r('''\n",
    "    library(Matrix); library(stringr); library(splines)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample run with R code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subsample the corpus to only consider articles mentioning 'monte carlo'\n",
    "cond_mat_mc = pd.read_csv('cond_mat_mc.csv')\n",
    "%Rpush cond_mat_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building corpus... \n",
      "Converting to Lower Case... \n",
      "Removing stopwords... \n",
      "Removing numbers... \n",
      "Removing punctuation... \n",
      "Stemming... \n",
      "Creating Output... \n",
      "Removing 8267 of 15095 terms (8267 of 363331 tokens) due to frequency \n",
      "Your corpus now has 6359 documents, 6828 terms and 355064 tokens."
     ]
    }
   ],
   "source": [
    "# Prep the corpus\n",
    "robjects.r('''\n",
    "    processed_corpus_temp = textProcessor(cond_mat_mc$abstract, metadata=cond_mat_mc, lowercase=TRUE)\n",
    "    processed_corpus = prepDocuments(processed_corpus_temp$documents,\n",
    "                                 processed_corpus_temp$vocab, \n",
    "                                 processed_corpus_temp$meta,\n",
    "                                 lower.thresh=1)\n",
    "    rm(processed_corpus_temp); invisible(gc())\n",
    "''');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "robjects.r('''\n",
    "    fit = stm(processed_corpus$documents, \n",
    "             processed_corpus$vocab,\n",
    "             K=20,\n",
    "             data=processed_corpus$meta,\n",
    "             init.type = 'Spectral',\n",
    "             seed=02138)\n",
    "''');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Initialization.\n",
      "\t Calculating the gram matrix...\n",
      "\t Finding anchor words...\n",
      " \t....................\n",
      "\t Recovering initialization...\n",
      " \t....................................................................\n",
      "Initialization complete.\n"
     ]
    }
   ],
   "source": [
    "robjects.r('''\n",
    "    documents <- fit$documents\n",
    "    vocab <- fit$vocab\n",
    "    settings <- fit$settings \n",
    "    model <- fit$model\n",
    "    verbose <- settings$verbose\n",
    "  ##########\n",
    "  #Step 1: Initialize Parameters\n",
    "  ##########\n",
    "    ngroups <- settings$ngroups\n",
    "  if(is.null(model)) {\n",
    "    if(verbose) cat(\"Beginning Initialization.\\n\")\n",
    "    #initialize\n",
    "    model <- stm.init(documents, settings)\n",
    "    #if we were using the Lee and Mimno method of setting K, update the settings\n",
    "    if(settings$dim$K==0) settings$dim$K <- nrow(model$beta[[1]])\n",
    "    #unpack\n",
    "    mu <- list(mu=model$mu)\n",
    "    sigma <- model$sigma\n",
    "    beta <- list(beta=model$beta)\n",
    "    if(!is.null(model$kappa)) beta$kappa <- model$kappa\n",
    "    lambda <- model$lambda\n",
    "    convergence <- NULL \n",
    "    #discard the old object\n",
    "    rm(model)\n",
    "  } else {\n",
    "    if(verbose) cat(\"Restarting Model...\\n\")\n",
    "    #extract from a standard STM object so we can simply continue.\n",
    "    mu <- model$mu\n",
    "    beta <- list(beta=lapply(model$beta$logbeta, exp))\n",
    "    if(!is.null(model$beta$kappa)) beta$kappa <- model$beta$kappa\n",
    "    sigma <- model$sigma\n",
    "    lambda <- model$eta\n",
    "    convergence <- model$convergence\n",
    "    #manually declare the model not converged or it will stop after the first iteration\n",
    "    convergence$stopits <- FALSE\n",
    "    convergence$converged <- FALSE\n",
    "    #iterate by 1 as that would have happened otherwise\n",
    "    convergence$its <- convergence$its + 1 \n",
    "  }    \n",
    "  \n",
    "  #Pull out some book keeping elements\n",
    "  ntokens <- sum(settings$dim$wcounts$x)\n",
    "  betaindex <- settings$covariates$betaindex\n",
    "  stopits <- FALSE\n",
    "  if(ngroups!=1) {\n",
    "    groups <- cut(1:length(documents), breaks=ngroups, labels=FALSE) \n",
    "  }\n",
    "  suffstats <- vector(mode=\"list\", length=ngroups)\n",
    "''');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rlist_2py(rlist):\n",
    "    return dict(zip(rlist.names,\n",
    "               list(rlist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fit = dict(zip( robjects.globalenv['fit'].names, \n",
    "         list( robjects.globalenv['fit'])))\n",
    "settings = dict(zip( fit['settings'].names, \n",
    "         list(fit['settings'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K, A, V, N = [int(settings['dim'][i][0]) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some setup for EM, retrieving the R objects\n",
    "stopits = False\n",
    "ngroups = int(robjects.globalenv['ngroups'][0])\n",
    "documents = [np.array(x) for x in list(robjects.globalenv['documents'])]\n",
    "beta_index = np.array(robjects.globalenv['betaindex'])\n",
    "beta = [np.array(x) for x in robjects.globalenv['beta'][0]]\n",
    "update_mu = True\n",
    "Lambda = np.array(robjects.globalenv['lambda'])\n",
    "mu = np.array(robjects.globalenv['mu'][0])\n",
    "sigma = np.array(robjects.globalenv['sigma'])\n",
    "verbose = settings['verbose'][0]\n",
    "\n",
    "# Run EM\n",
    "for i in range(2):\n",
    "    \n",
    "    # Non-blocked update\n",
    "    if ngroups==1:\n",
    "        # TODO\n",
    "        a = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to run all the necessary imports\n",
    "def run_imports(x):\n",
    "    import scipy as sp\n",
    "    import numpy as np\n",
    "    from scipy import optimize\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihood(eta, beta, doc_ct, mu, siginv):\n",
    "    exp_eta = np.exp(np.append(eta, np.array([0])))\n",
    "    ndoc = np.sum(doc_ct)\n",
    "    part1 = np.dot(np.log(np.dot(exp_eta, beta)), doc_ct) - ndoc * np.log(np.sum(exp_eta))\n",
    "    diff = mu.T - eta\n",
    "    part2 = 0.5 * float(np.dot(np.dot(diff, siginv), diff.T))\n",
    "    return part2 - part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad(eta, beta, doc_ct, mu, siginv):\n",
    "    exp_eta = np.exp(np.append(eta, [0]))\n",
    "    beta_prime = np.apply_along_axis(lambda x: x * exp_eta, 0, beta)\n",
    "    part1 = np.dot(beta_prime, doc_ct/np.sum(beta_prime, 0).T) - (np.sum(doc_ct)/ np.sum(exp_eta)) * exp_eta\n",
    "    diff = mu.T - eta\n",
    "    part2 = np.dot(siginv, diff.T)\n",
    "    part1 = part1[:len(part1)-1]\n",
    "    return (part2.T - part1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estep_docloop(doc_item, siginv, sigmaentropy):\n",
    "    doc_ct = doc_item['doc'][1]\n",
    "    eta = doc_item['init']\n",
    "    beta = doc_item['beta_i']\n",
    "    mu = doc_item['mu_i']\n",
    "    optim_par = sp.optimize.minimize(likelihood, eta, args=(beta, doc_ct, mu, siginv), \n",
    "                            method='BFGS')\n",
    "    \n",
    "    def hpb(eta, beta, doc_ct, mu, siginv, sigmaentropy):\n",
    "        \n",
    "        # Compute the Hessian\n",
    "        exp_eta = np.exp(np.append(eta, [0]))\n",
    "        theta = np.reshape(exp_eta/np.sum(exp_eta), (len(exp_eta), -1)).T\n",
    "        EB = np.apply_along_axis(lambda x: x * exp_eta, 0, beta)\n",
    "        EB = np.apply_along_axis(lambda x: x * (np.sqrt(doc_ct).T) / np.sum(EB,0), 1, EB)\n",
    "        hess = np.dot(EB, EB.T) - np.sum(doc_ct) * np.dot(theta.T, theta)    \n",
    "        EB = np.apply_along_axis(lambda x: x * np.sqrt(doc_ct).T, 1, EB)\n",
    "        hess[np.diag_indices_from(hess)] = hess[np.diag_indices_from(hess)] - np.sum(EB, 1) + np.sum(doc_ct) * theta\n",
    "        hess = hess[:hess.shape[0]-1,:hess.shape[1]-1] + siginv\n",
    "\n",
    "        # Invert via Cholesky decomposition\n",
    "        try:\n",
    "            nu = np.linalg.cholesky(hess)\n",
    "        except:\n",
    "            dvec = np.array(np.diag(hess))\n",
    "            magnitudes = np.sum(np.abs(hess), 1) - abs(dvec)\n",
    "            Km1 = len(dvec)\n",
    "            for i in range(Km1):\n",
    "                if dvec[i] < magnitudes[i]:\n",
    "                    dvec[i] = magnitudes[i]\n",
    "            hess[np.diag_indices_from(hess)] = dvec\n",
    "            nu = np.linalg.cholesky(hess)\n",
    "\n",
    "        # Finish construction\n",
    "        det_term = -np.sum(np.log(np.diag(nu)))\n",
    "        nu = np.linalg.inv(np.triu(nu))\n",
    "        nu = np.dot(nu, nu.T)\n",
    "        diff = eta - mu.flatten()\n",
    "\n",
    "        # Compute the bound\n",
    "        bound = (np.dot(np.log(np.dot(theta, beta)), doc_ct) + det_term \n",
    "                 - 0.5 * np.dot(diff.T, np.dot(siginv, diff)) - sigmaentropy)\n",
    "\n",
    "        # Construct ouput\n",
    "        out = {'phis': EB,\n",
    "               'eta': {'lambda': eta, 'nu': nu},\n",
    "               'bound': bound}\n",
    "        return out\n",
    "    \n",
    "    return hpb(optim_par.x, beta, doc_ct, mu, siginv, sigmaentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def estep_spark(documents, beta_index, beta, Lambda_old,\n",
    "                mu, sigma, verbose, sc, update_mu=False):\n",
    "    \n",
    "    # Initialize sufficient statistics\n",
    "    sigma_ss = np.zeros((K-1, K-1))\n",
    "    beta_ss = [np.zeros((K, V)) for i in range(A)]\n",
    "    bound = np.array([0] * N)\n",
    "    Lambda = np.array([0] * N)\n",
    "    siginv = np.linalg.inv(sigma)\n",
    "    sigmaentropy = np.log(np.abs(np.linalg.det(sigma))) * 0.5\n",
    "    \n",
    "    # Parallelize document collection\n",
    "    collection = [{'doc':doc, 'aspect': int(aspect), 'init': init} \n",
    "                  for (doc, aspect, init) in zip(documents, beta_index, Lambda_old)]\n",
    "    for item in collection:\n",
    "        item['beta_i'] = beta[item['aspect']-1][:,[x-1 for x in item['doc'][0]]]\n",
    "        item['mu_i'] = mu\n",
    "        \n",
    "    # Run the imports\n",
    "    imports_return = sc.parallelize(range(100)).map(run_imports).collect()\n",
    "        \n",
    "    # Run estep on just a few samples for testing purposes\n",
    "    collection_par = sc.parallelize(collection[:5])\n",
    "    out = collection_par.map(lambda x: estep_docloop(x, siginv, sigmaentropy)).collect()\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta': {'nu': array([[ 12.9133492 ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,  16.98471722,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,  14.3728152 ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   3.40251017,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         21.09976472,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,  14.66753209,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  16.71529389,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,  13.68261609,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         17.66749152,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,  17.27986716,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  15.9751339 ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,  14.25200166,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         14.62523477,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,  18.37257955,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  14.39582226,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,  15.32706898,\n",
      "          0.        ,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "         14.05237507,   0.        ,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,  23.76837755,   0.        ],\n",
      "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,   0.        ,   0.        ,\n",
      "          0.        ,   0.        ,  16.1142136 ]]), 'lambda': array([-0.54992063, -0.17801445, -0.39253748,  5.63232902,  0.05281877,\n",
      "       -0.38718144, -0.20297509, -0.5022322 , -0.13452668, -0.16159979,\n",
      "       -0.26300883, -0.43506017, -0.39431116, -0.08991052, -0.42026474,\n",
      "       -0.32383676, -0.46197746,  0.15648698, -0.25332788])}, 'phis': array([[  2.19683197e-03,   1.96435275e-03,   7.19562505e-05, ...,\n",
      "          1.29356383e-03,   9.79315012e-04,   1.72501875e-03],\n",
      "       [  2.35410581e-03,   3.38555759e-03,   2.90619313e-03, ...,\n",
      "          2.85223522e-03,   2.52276103e-03,   3.01132209e-03],\n",
      "       [  3.34015454e-03,   2.24043559e-03,   1.82746832e-03, ...,\n",
      "          3.02713715e-03,   2.68254787e-03,   2.33519475e-03],\n",
      "       ..., \n",
      "       [  3.64873419e-03,   4.65964574e-03,   4.44014264e-03, ...,\n",
      "          3.32793227e-03,   3.44740249e-03,   4.06985168e-03],\n",
      "       [  2.25049400e-03,   2.89440089e-03,   2.65213068e-03, ...,\n",
      "          2.48131501e-03,   2.23108384e-03,   2.91546787e-03],\n",
      "       [  2.52629336e-03,   3.86723741e-03,   2.03460243e-03, ...,\n",
      "          3.49183101e-03,   2.08595776e-03,   3.10304792e-03]]), 'bound': array([-398.84286973])}\n"
     ]
    }
   ],
   "source": [
    "# A trial run of the E-step\n",
    "trial_run = estep_spark(documents, beta_index, beta, Lambda, mu, sigma, verbose, sc, False)\n",
    "print trial_run[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.5.0)",
   "language": "python",
   "name": "pyspark"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
